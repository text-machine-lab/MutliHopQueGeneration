{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "8648ffee-4b23-4940-9f40-cc1655b43473",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8 supp 1001500\n",
      "8 supp 1003000\n",
      "8 all 1001000\n",
      "8 all 1003000\n",
      "16 supp 1000500\n",
      "16 supp 1003000\n",
      "16 all 1002000\n",
      "16 all 1003000\n",
      "32 supp 1003000\n",
      "32 all 1002500\n",
      "32 all 1003000\n",
      "64 supp 1001500\n",
      "64 supp 1005120\n",
      "64 all 1004000\n",
      "64 all 1005120\n",
      "128 supp 1009500\n",
      "128 supp 1010240\n",
      "128 all 1006000\n",
      "128 all 1010240\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import re\n",
    "\n",
    "import tensorflow.compat.v1 as tf\n",
    "\n",
    "from statistics import mean\n",
    "from collections import defaultdict\n",
    "\n",
    "from pycocoevalcap.bleu.bleu import Bleu\n",
    "from pycocoevalcap.meteor.meteor import Meteor\n",
    "from pycocoevalcap.rouge.rouge import Rouge\n",
    "\n",
    "shots = [8,16,32,64,128]\n",
    "supports = ['supp', 'all']\n",
    "\n",
    "b4m, mm, rm = Bleu(4), Meteor(), Rouge()\n",
    "\n",
    "bleu4 = lambda targets, predictions: {'bleu4': 100 * mean([b4m.compute_score({i:[targets[i]]}, {i:[predictions[i]]})[0][3] for i in range(len(targets))])}\n",
    "bleu3 = lambda targets, predictions: {'bleu3': 100 * mean([b4m.compute_score({i:[targets[i]]}, {i:[predictions[i]]})[0][2] for i in range(len(targets))])}\n",
    "bleu2 = lambda targets, predictions: {'bleu2': 100 * mean([b4m.compute_score({i:[targets[i]]}, {i:[predictions[i]]})[0][1] for i in range(len(targets))])}\n",
    "bleu1 = lambda targets, predictions: {'bleu1': 100 * mean([b4m.compute_score({i:[targets[i]]}, {i:[predictions[i]]})[0][0] for i in range(len(targets))])}\n",
    "\n",
    "rouge = lambda targets, predictions: {'rougeL': 100 * mean([rm.compute_score({i:[targets[i]]}, {i:[predictions[i]]})[0] for i in range(len(targets))])}\n",
    "\n",
    "def meteor(targets, predictions):\n",
    "    from pycocoevalcap.meteor.meteor import Meteor\n",
    "    return {'meteor': 100 * mean([mm.compute_score({i:[targets[i]]}, {i:[predictions[i]]})[0] for i in range(len(targets))])}\n",
    "\n",
    "def remove_tags_and_strip(string, **unused_kwargs): \n",
    "    return re.sub('<extra_id_[0-9]{1,2}>', '', string).strip()\n",
    "\n",
    "def readlines_into_list_gf(path):\n",
    "    with tf.io.gfile.GFile(path) as f:\n",
    "        return [l.strip() for l in f.readlines()]\n",
    "\n",
    "predictions = defaultdict(lambda: defaultdict(lambda: {'best_checkpoint': None, \"all_checkpoint_data\": None}))\n",
    "\n",
    "import contextlib\n",
    "\n",
    "\n",
    "for shot in shots:\n",
    "    for support in supports:\n",
    "        MODEL_DIR = f'gs://t5_fewshot_mqg/models/t5_baseline_0/3B/{shot}_SHOT/{support}/test_eval/'\n",
    "        gold_fp = os.path.join(MODEL_DIR, 'fhpqg_no_rationale_targets')\n",
    "        gold = readlines_into_list_gf(gold_fp)\n",
    "        checkpoints = [int(p.split('_')[-2]) for p in tf.io.gfile.glob(os.path.join(MODEL_DIR, 'fhpqg_no_rationale_*_predictions'))]\n",
    "        checkpoint_predictions = defaultdict(lambda: {\"predictions\":None, \n",
    "                                                      \"bleu4\": None, \n",
    "                                                      \"bleu3\": None, \n",
    "                                                      \"bleu2\": None, \n",
    "                                                      \"bleu1\": None, \n",
    "                                                      \"rouge\": None, \n",
    "                                                      \"meteor\": None,\n",
    "                                                      \"average\": None}\n",
    "                                            )\n",
    "        for checkpoint in checkpoints:\n",
    "            print(shot, support, checkpoint)\n",
    "            checkpoint_predictions_fp = os.path.join(MODEL_DIR, f\"fhpqg_no_rationale_{checkpoint}_predictions\")\n",
    "            x = readlines_into_list_gf(checkpoint_predictions_fp)\n",
    "            try:\n",
    "                assert len(x) == len(gold)\n",
    "            except:\n",
    "                continue\n",
    "            checkpoint_predictions[checkpoint][\"predictions\"] = x\n",
    "            with contextlib.redirect_stdout(None):\n",
    "                checkpoint_predictions[checkpoint][\"bleu4\"] = bleu4(gold, checkpoint_predictions[checkpoint][\"predictions\"])['bleu4']\n",
    "                checkpoint_predictions[checkpoint][\"bleu3\"] = bleu3(gold, checkpoint_predictions[checkpoint][\"predictions\"])['bleu3']\n",
    "                checkpoint_predictions[checkpoint][\"bleu2\"] = bleu2(gold, checkpoint_predictions[checkpoint][\"predictions\"])['bleu2']\n",
    "                checkpoint_predictions[checkpoint][\"bleu1\"] = bleu1(gold, checkpoint_predictions[checkpoint][\"predictions\"])['bleu1']\n",
    "            checkpoint_predictions[checkpoint][\"meteor\"] = meteor(gold, checkpoint_predictions[checkpoint][\"predictions\"])['meteor']\n",
    "            checkpoint_predictions[checkpoint][\"rouge\"] = rouge(gold, checkpoint_predictions[checkpoint][\"predictions\"])['rougeL']\n",
    "            checkpoint_predictions[checkpoint][\"average\"] = mean([\n",
    "                checkpoint_predictions[checkpoint][\"bleu4\"],\n",
    "                checkpoint_predictions[checkpoint][\"bleu3\"],\n",
    "                checkpoint_predictions[checkpoint][\"bleu2\"],\n",
    "                checkpoint_predictions[checkpoint][\"bleu1\"],\n",
    "                checkpoint_predictions[checkpoint][\"meteor\"],\n",
    "                checkpoint_predictions[checkpoint][\"rouge\"]\n",
    "            ])\n",
    "        predictions[shot][support]['all_checkpoint_data'] = checkpoint_predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "b8a60112-d670-4545-aaba-0858973b66c5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8, supp\n",
      "1001500: 15.33\n",
      "best_checkpoint 1001500 @ 15.33\n",
      "8, all\n",
      "1001000: 15.16\n",
      "best_checkpoint 1001000 @ 15.16\n",
      "16, supp\n",
      "1000500: 15.95\n",
      "best_checkpoint 1000500 @ 15.95\n",
      "16, all\n",
      "1002000: 16.47\n",
      "best_checkpoint 1002000 @ 16.47\n",
      "32, supp\n",
      "1003000: 18.76\n",
      "best_checkpoint 1003000 @ 18.76\n",
      "32, all\n",
      "1002500: 17.89\n",
      "best_checkpoint 1002500 @ 17.89\n",
      "64, supp\n",
      "1001500: 19.32\n",
      "best_checkpoint 1001500 @ 19.32\n",
      "64, all\n",
      "1004000: 18.69\n",
      "best_checkpoint 1004000 @ 18.69\n",
      "128, supp\n",
      "1009500: 21.48\n",
      "best_checkpoint 1009500 @ 21.48\n",
      "128, all\n",
      "1006000: 19.37\n",
      "best_checkpoint 1006000 @ 19.37\n"
     ]
    }
   ],
   "source": [
    "import copy\n",
    "\n",
    "backup1 = copy.deepcopy(backup2)\n",
    "predictions = backup2\n",
    "for shot in shots:\n",
    "    for support in supports:\n",
    "        checkpoint_predictions = predictions[shot][support]['all_checkpoint_data']\n",
    "        avg_scores_across_all_checkpoints = [checkpoint_predictions[chkpt]['average'] for chkpt in checkpoint_predictions]\n",
    "        all_checkpoints = [chkpt for chkpt in checkpoint_predictions]\n",
    "        try:\n",
    "            max_avg_score = max(avg_scores_across_all_checkpoints)\n",
    "        except:\n",
    "            print(shot, support, avg_scores_across_all_checkpoints)\n",
    "            raise Exception\n",
    "        for chkpt in checkpoint_predictions:\n",
    "            if checkpoint_predictions[chkpt]['average'] == max_avg_score:\n",
    "                predictions[shot][support]['best_checkpoint'] = chkpt\n",
    "                print(f\"{shot}, {support}\")\n",
    "                for i, c in enumerate(avg_scores_across_all_checkpoints):\n",
    "                    print(f\"{all_checkpoints[i]}: {c:.2f}\")\n",
    "                print(f\"best_checkpoint {chkpt} @ {max_avg_score:.2f}\")\n",
    "                # for metric_name in ['bleu4', 'bleu3', 'bleu2', 'bleu1', 'meteor', 'rouge']:\n",
    "                #     print(f\"best_checkpoint {chkpt} @ {metric_name}, {predictions[shot][support]['all_checkpoint_data'][chkpt][metric_name]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "79d7079b-402f-4ee5-9faa-76a921008e70",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8 supp top 1001500\n",
      "bleu1, 24.40\n",
      "bleu2, 13.76\n",
      "bleu3, 7.49\n",
      "bleu4, 4.50\n",
      "meteor, 17.18\n",
      "rouge, 24.63\n",
      "\n",
      "8 all top 1001000\n",
      "bleu1, 24.17\n",
      "bleu2, 13.46\n",
      "bleu3, 7.38\n",
      "bleu4, 4.46\n",
      "meteor, 16.79\n",
      "rouge, 24.71\n",
      "\n",
      "16 supp top 1000500\n",
      "bleu1, 24.47\n",
      "bleu2, 14.37\n",
      "bleu3, 8.39\n",
      "bleu4, 5.33\n",
      "meteor, 17.93\n",
      "rouge, 25.21\n",
      "\n",
      "16 all top 1002000\n",
      "bleu1, 25.61\n",
      "bleu2, 15.04\n",
      "bleu3, 8.76\n",
      "bleu4, 5.47\n",
      "meteor, 18.74\n",
      "rouge, 25.18\n",
      "\n",
      "32 supp top 1003000\n",
      "bleu1, 28.27\n",
      "bleu2, 17.63\n",
      "bleu3, 10.84\n",
      "bleu4, 7.03\n",
      "meteor, 21.00\n",
      "rouge, 27.77\n",
      "\n",
      "32 all top 1002500\n",
      "bleu1, 27.04\n",
      "bleu2, 16.75\n",
      "bleu3, 10.23\n",
      "bleu4, 6.64\n",
      "meteor, 20.31\n",
      "rouge, 26.39\n",
      "\n",
      "64 supp top 1001500\n",
      "bleu1, 28.74\n",
      "bleu2, 18.19\n",
      "bleu3, 11.44\n",
      "bleu4, 7.59\n",
      "meteor, 21.78\n",
      "rouge, 28.20\n",
      "\n",
      "64 all top 1004000\n",
      "bleu1, 28.06\n",
      "bleu2, 17.52\n",
      "bleu3, 10.89\n",
      "bleu4, 7.14\n",
      "meteor, 21.11\n",
      "rouge, 27.42\n",
      "\n",
      "128 supp top 1009500\n",
      "bleu1, 31.42\n",
      "bleu2, 20.53\n",
      "bleu3, 13.34\n",
      "bleu4, 8.94\n",
      "meteor, 24.02\n",
      "rouge, 30.62\n",
      "\n",
      "128 all top 1006000\n",
      "bleu1, 28.31\n",
      "bleu2, 18.05\n",
      "bleu3, 11.41\n",
      "bleu4, 7.60\n",
      "meteor, 22.65\n",
      "rouge, 28.18\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for shot in shots:\n",
    "    for support in supports:\n",
    "        checkpoint_predictions = predictions[shot][support]['all_checkpoint_data']\n",
    "        chkpt = predictions[shot][support]['best_checkpoint']\n",
    "        print(f'{shot} {support} top {chkpt}')\n",
    "        for metric_name in ['bleu1', 'bleu2', 'bleu3', 'bleu4', 'meteor', 'rouge']:\n",
    "            print(f\"{metric_name}, {checkpoint_predictions[chkpt][metric_name]:.2f}\")\n",
    "        print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03a20afc-e498-47e0-8316-2ad81c5db268",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "with open('data.json', 'r') as f:\n",
    "    predict_data = json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41552cfe-7307-4aea-ab67-c40ed2197b5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "gold_fp[30]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8eb843b5-f790-4ec2-a80f-30a910da9797",
   "metadata": {},
   "outputs": [],
   "source": [
    "targets, predictions = [], []\n",
    "for i in range(len(predict_data)):\n",
    "    gold = predict_data[i]['gold_q']\n",
    "    predq = predict_data[i].get('q', None)\n",
    "    if predq != None:\n",
    "        targets.append(gold)\n",
    "        predictions.append(remove_tags_and_strip(predq))\n",
    "    gold = predict_data[i]['gold_q']\n",
    "    predq = predict_data[i].get('q_c', None)\n",
    "    if predq != None:\n",
    "        targets.append(gold)\n",
    "        predictions.append(remove_tags_and_strip(predq))\n",
    "        \n",
    "b4 = bleu4(targets, predictions)\n",
    "b3 = bleu3(targets, predictions)\n",
    "b2 = bleu2(targets, predictions)\n",
    "b1 = bleu1(targets, predictions)\n",
    "r = rouge(targets, predictions)\n",
    "m = meteor(targets, predictions)\n",
    "\n",
    "metrics = {}\n",
    "metrics.update(b4)\n",
    "metrics.update(b3)\n",
    "metrics.update(b2)\n",
    "metrics.update(b1)\n",
    "metrics.update(r)\n",
    "metrics.update(m)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09ecc478-1c16-4180-8f87-43ba2cd567ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "', '.join([f\"{key}: {metrics[key]:.2f}\" for key in sorted(metrics.keys())])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4788b36f-f9f0-4936-9787-e6bcf767ba23",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow.compat.v1 as tf\n",
    "import os\n",
    "\n",
    "eval_checkpoints =  [int(fp.split('-')[-1][:-5]) for fp in tf.io.gfile.glob(os.path.join(MODEL_DIR, 'model.ckpt-*.meta'))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8af9004c-80d5-4fd0-a73a-3c9b1395b20e",
   "metadata": {},
   "outputs": [],
   "source": [
    "eval_checkpoints"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e9c9093-6b5d-4d04-9864-8376418fd0be",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "s = time.time()\n",
    "time.sleep(10)\n",
    "e = time.time()\n",
    "\n",
    "print(e-s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b665b52d-f86d-498b-b0d8-894446c89782",
   "metadata": {},
   "outputs": [],
   "source": [
    "e = sorted(eval_checkpoints, reverse=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79d44a40-a785-497f-aa61-9c979e2503f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "MODEL\n",
    "eval_jsons =  [int(fp.split('-')[-1][:-5]) for fp in tf.io.gfile.glob(os.path.join(MODEL_DIR, 'model.ckpt-*.meta'))]\n",
    "eval_checkpoints = sorted(eval_checkpoints, reverse=True)\n",
    "print(f\"Found checkpoints eval_checkpoints: {eval_checkpoints}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "t5env",
   "language": "python",
   "name": "t5env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
